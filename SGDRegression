from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import SGDRegressor
from sklearn.preprocessing import StandardScaler
# ..........................................
songs = numpy.load("songs50k.npy")
X_train, X_val, y_train, y_val = train_test_split(songs[:,1:], songs[:,0], test_size=1/3, random_state=666)

scaler = StandardScaler()
scaler.fit(X_train)
X_train_z = scaler.transform(X_train) ## fit the X_train and transform to z value as SGD is very sensitive to LR and 
X_val_z = scaler.transform(X_val) ## scale features.

## Create learning rate from 10 raised to the power of -6 to 1

learning_rate = []
for x in range(-6,1):
    learning_rate.append(10**x)

settings = []

## lr_schedule is Learning Rate Schedule

for lr_schedule in ["constant", "optimal", "invscaling"]:
    for eta0 in learning_rate:
        model = SGDRegressor(learning_rate = lr_schedule, eta0 = eta0, random_state = 666)
        
        # fit the model
        
        model.fit(X_train_z,y_train)
        
        # Calculate MAE and r^2
        mae = mean_absolute_error(y_val, model.predict(X_val_z))
        r2 = r2_score(y_val, model.predict(X_val_z))
        settings.append((lr_schedule, eta0, mae, r2))
        print(settings[-1]) ## Print the latest added value

# Calculate best MAE and R^2

best_mae = min(settings, key = lambda x : x[-2])
best_r2 = max(settings, key = lambda x : x[-1])

# Print the best MAE and R^2

print("The best settings according to: \n (1) MAE is {} ; \n (2) according to R^2 is {} ".format(best_mae, best_r2))
